{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cd0adc-60ff-4e8c-9a36-43f59ce578de",
   "metadata": {},
   "source": [
    "# Sentence embeddings\n",
    "We will mainly use `sentence-transformers`, which is a dedicated package from Hugging Face ðŸ¤—. \n",
    "\n",
    "Relevant documentation\n",
    "- Semantic textual similarity https://www.sbert.net/docs/usage/semantic_textual_similarity.html\n",
    "- Semantic search https://www.sbert.net/examples/applications/semantic-search/README.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f070d4c-1c9b-4af9-9b22-d357e07c0ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers faiss-cpu langchain langchain-community \"unstructured[all-docs]\" openai nest-asyncio streamlit jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed070c3-50f0-4d3c-ad73-4b5fef706279",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### From word embeddings to sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fd65a-d607-4a2f-8e46-c07bb71ec11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee6e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Sentences we want to encode. Example:\n",
    "sentence = ['This framework generates embeddings for each input sentence']\n",
    "\n",
    "# Sentences are encoded by calling model.encode()\n",
    "embedding = model.encode(sentence)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ba9e8-82a7-458b-97ab-d9af7f2555a5",
   "metadata": {},
   "source": [
    "See, a sentence embedding is just a vector, just like a word embedding. That means we can also calculate similarities in a similar way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5113acd-53a0-47bd-a7b6-d1f072b0baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome!']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'My plants look a bit sick, could it be bitrot?',\n",
    "              'The new movie is so great!']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f74a88-c711-4b1b-a7cc-8a7a473c2478",
   "metadata": {},
   "source": [
    "## Semantic search and retrieval\n",
    "\n",
    "The idea behind semantic search is to embed all entries in your corpus, whether they be sentences, paragraphs, or documents, into a vector space.\n",
    "\n",
    "At search time, the query is embedded into the same vector space and the closest embeddings from your corpus are found. These entries should have a high semantic overlap with the query.\n",
    "\n",
    "\n",
    "![title](https://raw.githubusercontent.com/UKPLab/sentence-transformers/master/docs/img/SemanticSearch.png\n",
    ")\n",
    "\n",
    "Instead of trying to build a semantic search engine from first principles, we'll use `langchain`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08117fa3-80b8-4138-bf75-d540930084a7",
   "metadata": {},
   "source": [
    "## [Don't run this again] Crawl the Vlerick website using Apify\n",
    "\n",
    "The following code crawls the Vlerick website so we have some text to model. It's just example code. \n",
    "\n",
    "Langchain supports more than 100 integrations, so depending on where you find interesting data you'll need to use something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331bd23b-1ccd-4e2c-8ca5-cc5f95381879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.utilities import ApifyWrapper\n",
    "# import os\n",
    "\n",
    "# os.environ[\"APIFY_API_TOKEN\"] = \"\"\n",
    "\n",
    "# apify = ApifyWrapper()\n",
    "# # Call the Actor to obtain text from the crawled webpages\n",
    "# loader = apify.call_actor(\n",
    "#     actor_id=\"apify/website-content-crawler\",\n",
    "#     run_input={\n",
    "#         \"startUrls\": [{\"url\": \"https://www.vlerick.com/en/\"}]\n",
    "#     },\n",
    "#     dataset_mapping_function=lambda item: Document(\n",
    "#         page_content=item[\"text\"] or \"\", metadata={\"source\": item[\"url\"]}\n",
    "#     ),\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117d9c0-64a1-42ef-80e5-0beec692644a",
   "metadata": {},
   "source": [
    "## Create new vector store and embed all documents\n",
    "Source: https://python.langchain.com/docs/expression_language/cookbook/retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b604e3e2-ff3f-4e40-ba93-1d55d5698bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load all documents\n",
    "# Adapt this code to your own source of data.\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader, JSONLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ac200d-b25e-445d-92da-9539609e70c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\VLERICK\\NLP\\vlerick-mai-nlp-2023\\.env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents 1\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "loader = DirectoryLoader('DataFiles', silent_errors=True)\n",
    "course_docs = loader.load()\n",
    "\n",
    "print(f\"Number of documents {len(course_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e88ba1-b915-46ef-88af-63fbd50f4153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'DataFiles\\\\MÃ©moire - Mathieu Demarets - MASTER.pdf'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd20bfb-5cc4-475b-a6b8-e6555e3f84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from langchain_community.document_loaders import ApifyDatasetLoader\n",
    "# from langchain_community.document_loaders.base import Document\n",
    "\n",
    "# loader = ApifyDatasetLoader(\n",
    "#     dataset_id=\"RcArHfVs80xOg9IKs\",\n",
    "#     dataset_mapping_function=lambda dataset_item: Document(\n",
    "#         page_content=dataset_item[\"text\"], metadata={\"source\": dataset_item[\"url\"]}\n",
    "#     ),\n",
    "# )\n",
    "# website_docs = loader.load()\n",
    "# print(f\"Number of documents {len(website_docs)}\")\n",
    "# website_docs = [doc for doc in website_docs if not doc.page_content.startswith(\"Your choice regarding cookies on this site\")]\n",
    "# print(f\"Number of non-trivial documents {len(website_docs)}\")\n",
    "# website_docs[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc75d6-a218-4c49-8949-35c8fed54a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# documents = text_splitter.split_documents(course_docs + website_docs)\n",
    "# documents[0]\n",
    "# print(f\"Number of chunks {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3316d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1627, which is longer than the specified 1000\n",
      "Created a chunk of size 1801, which is longer than the specified 1000\n",
      "Created a chunk of size 1447, which is longer than the specified 1000\n",
      "Created a chunk of size 1279, which is longer than the specified 1000\n",
      "Created a chunk of size 1569, which is longer than the specified 1000\n",
      "Created a chunk of size 1100, which is longer than the specified 1000\n",
      "Created a chunk of size 1122, which is longer than the specified 1000\n",
      "Created a chunk of size 1082, which is longer than the specified 1000\n",
      "Created a chunk of size 1250, which is longer than the specified 1000\n",
      "Created a chunk of size 1027, which is longer than the specified 1000\n",
      "Created a chunk of size 1393, which is longer than the specified 1000\n",
      "Created a chunk of size 1214, which is longer than the specified 1000\n",
      "Created a chunk of size 1122, which is longer than the specified 1000\n",
      "Created a chunk of size 1390, which is longer than the specified 1000\n",
      "Created a chunk of size 1504, which is longer than the specified 1000\n",
      "Created a chunk of size 1906, which is longer than the specified 1000\n",
      "Created a chunk of size 1982, which is longer than the specified 1000\n",
      "Created a chunk of size 1060, which is longer than the specified 1000\n",
      "Created a chunk of size 1080, which is longer than the specified 1000\n",
      "Created a chunk of size 1119, which is longer than the specified 1000\n",
      "Created a chunk of size 1658, which is longer than the specified 1000\n",
      "Created a chunk of size 1657, which is longer than the specified 1000\n",
      "Created a chunk of size 1468, which is longer than the specified 1000\n",
      "Created a chunk of size 1698, which is longer than the specified 1000\n",
      "Created a chunk of size 1395, which is longer than the specified 1000\n",
      "Created a chunk of size 1479, which is longer than the specified 1000\n",
      "Created a chunk of size 1397, which is longer than the specified 1000\n",
      "Created a chunk of size 1057, which is longer than the specified 1000\n",
      "Created a chunk of size 1242, which is longer than the specified 1000\n",
      "Created a chunk of size 1449, which is longer than the specified 1000\n",
      "Created a chunk of size 1730, which is longer than the specified 1000\n",
      "Created a chunk of size 1255, which is longer than the specified 1000\n",
      "Created a chunk of size 1229, which is longer than the specified 1000\n",
      "Created a chunk of size 1434, which is longer than the specified 1000\n",
      "Created a chunk of size 1123, which is longer than the specified 1000\n",
      "Created a chunk of size 1739, which is longer than the specified 1000\n",
      "Created a chunk of size 1398, which is longer than the specified 1000\n",
      "Created a chunk of size 2190, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1119, which is longer than the specified 1000\n",
      "Created a chunk of size 1332, which is longer than the specified 1000\n",
      "Created a chunk of size 1057, which is longer than the specified 1000\n",
      "Created a chunk of size 1007, which is longer than the specified 1000\n",
      "Created a chunk of size 1128, which is longer than the specified 1000\n",
      "Created a chunk of size 1460, which is longer than the specified 1000\n",
      "Created a chunk of size 1034, which is longer than the specified 1000\n",
      "Created a chunk of size 1101, which is longer than the specified 1000\n",
      "Created a chunk of size 1531, which is longer than the specified 1000\n",
      "Created a chunk of size 1370, which is longer than the specified 1000\n",
      "Created a chunk of size 1335, which is longer than the specified 1000\n",
      "Created a chunk of size 1257, which is longer than the specified 1000\n",
      "Created a chunk of size 1462, which is longer than the specified 1000\n",
      "Created a chunk of size 1235, which is longer than the specified 1000\n",
      "Created a chunk of size 1126, which is longer than the specified 1000\n",
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 1439, which is longer than the specified 1000\n",
      "Created a chunk of size 1050, which is longer than the specified 1000\n",
      "Created a chunk of size 1196, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks 352\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(course_docs)\n",
    "documents[0]\n",
    "print(f\"Number of chunks {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d4428-d9b8-4b62-be3d-cbed5058fe6c",
   "metadata": {},
   "source": [
    "### Embed into a vector store - and cache the results\n",
    "We got a decent store of data loaded into memory now. Next thing we need to do is calculate sentence embeddings. \n",
    "We'll use simple, reasonably fast embeddings that we can calculate locally withouting requiring an expensive GPU or cloud service like OpenAI's GPTx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ed4206-743d-4e72-b471-e2e300642645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 672 ms\n",
      "Wall time: 290 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.05774908512830734,\n",
       " 0.013756634667515755,\n",
       " 0.001040166593156755,\n",
       " 0.08255515247583389,\n",
       " -0.05679449439048767,\n",
       " -0.15898311138153076,\n",
       " 0.007460128050297499,\n",
       " -0.014039515517652035,\n",
       " -0.031627457588911057,\n",
       " -0.012654372490942478,\n",
       " 0.017630746588110924,\n",
       " -0.054090578109025955,\n",
       " 0.059190746396780014,\n",
       " -0.007160970475524664,\n",
       " -0.03616929054260254,\n",
       " 0.04178224876523018,\n",
       " -0.07770746201276779,\n",
       " -0.08017875999212265,\n",
       " 0.03506764397025108,\n",
       " -0.04065043479204178,\n",
       " -0.03000565804541111,\n",
       " -0.04816131666302681,\n",
       " -0.07166736572980881,\n",
       " -0.039035994559526443,\n",
       " 0.06581778079271317,\n",
       " 0.07236869633197784,\n",
       " 0.04865185171365738,\n",
       " 0.028237324208021164,\n",
       " -0.014162116684019566,\n",
       " 0.052932944148778915,\n",
       " -0.053758103400468826,\n",
       " -0.011664408259093761,\n",
       " 0.0281183123588562,\n",
       " 0.06605266034603119,\n",
       " -0.0374017171561718,\n",
       " -0.0032199635170400143,\n",
       " 0.023476196452975273,\n",
       " 0.06544357538223267,\n",
       " -0.0049888635985553265,\n",
       " 0.019189277663826942,\n",
       " -0.060288410633802414,\n",
       " -0.028808731585741043,\n",
       " 0.012724922969937325,\n",
       " -0.007536690216511488,\n",
       " -0.0615227185189724,\n",
       " 0.0280728992074728,\n",
       " 0.038668494671583176,\n",
       " -0.06398429721593857,\n",
       " -0.047909028828144073,\n",
       " 0.017111334949731827,\n",
       " -0.08139479905366898,\n",
       " -0.00978880189359188,\n",
       " 0.011136885732412338,\n",
       " 0.0003460929438006133,\n",
       " 0.005185331217944622,\n",
       " -0.012379695661365986,\n",
       " 0.05264773592352867,\n",
       " 0.07690317928791046,\n",
       " -0.023576462641358376,\n",
       " 0.0774303451180458,\n",
       " -0.027767717838287354,\n",
       " -0.04918251931667328,\n",
       " -0.05975833535194397,\n",
       " 0.03433756157755852,\n",
       " 0.08177240937948227,\n",
       " -0.041326992213726044,\n",
       " -0.031076349318027496,\n",
       " 0.0034035409335047007,\n",
       " 0.020834019407629967,\n",
       " -0.1227509155869484,\n",
       " -0.042041145265102386,\n",
       " 0.010954577475786209,\n",
       " -0.011474641971290112,\n",
       " 0.04436422884464264,\n",
       " 0.06882410496473312,\n",
       " -0.06141290441155434,\n",
       " -0.035387977957725525,\n",
       " 0.0066810776479542255,\n",
       " 0.10374702513217926,\n",
       " -0.021177710965275764,\n",
       " -0.0025911645498126745,\n",
       " -0.023950165137648582,\n",
       " -0.08054754137992859,\n",
       " 0.02354051172733307,\n",
       " -0.0016536620678380132,\n",
       " -0.005969870835542679,\n",
       " -0.04304477944970131,\n",
       " 0.08298157900571823,\n",
       " -0.05899239331483841,\n",
       " -0.015049316920340061,\n",
       " 0.06993994116783142,\n",
       " 0.0004201061383355409,\n",
       " 0.011762971058487892,\n",
       " 0.09820720553398132,\n",
       " -0.07349710911512375,\n",
       " -0.004394121468067169,\n",
       " -0.027309531345963478,\n",
       " 0.01556992344558239,\n",
       " -0.005763344932347536,\n",
       " -0.047034215182065964,\n",
       " -0.02960340678691864,\n",
       " 0.030030803754925728,\n",
       " 0.00797577016055584,\n",
       " 0.10725703090429306,\n",
       " -0.00869783852249384,\n",
       " 0.0037025134079158306,\n",
       " -0.03274315223097801,\n",
       " -0.038692817091941833,\n",
       " -0.020028065890073776,\n",
       " -0.0006219466449692845,\n",
       " -0.04283805936574936,\n",
       " 0.07826682925224304,\n",
       " 0.02141190879046917,\n",
       " 0.05222531780600548,\n",
       " -0.036241769790649414,\n",
       " -0.017672639340162277,\n",
       " -0.1831667423248291,\n",
       " 0.06590714305639267,\n",
       " -0.03659489005804062,\n",
       " 0.03315919637680054,\n",
       " -0.048084013164043427,\n",
       " -0.012863470241427422,\n",
       " -0.043114397674798965,\n",
       " -0.030045824125409126,\n",
       " -0.011857767589390278,\n",
       " -0.03920121118426323,\n",
       " -0.05180232226848602,\n",
       " -3.9656712518210856e-33,\n",
       " 0.02145889401435852,\n",
       " -0.028130708262324333,\n",
       " -0.04497550427913666,\n",
       " 0.010436349548399448,\n",
       " 0.039339084178209305,\n",
       " -0.05781584233045578,\n",
       " -0.024422265589237213,\n",
       " 0.06777027994394302,\n",
       " 0.0024842622224241495,\n",
       " 0.07585171610116959,\n",
       " -0.02768164873123169,\n",
       " 0.03270988538861275,\n",
       " -0.021037302911281586,\n",
       " 0.03260656073689461,\n",
       " 0.07985714077949524,\n",
       " 0.03654256463050842,\n",
       " -0.05045374110341072,\n",
       " 0.038170453161001205,\n",
       " -0.09522424638271332,\n",
       " 0.0354829803109169,\n",
       " 0.03406624123454094,\n",
       " -0.006904652342200279,\n",
       " 0.06316321343183517,\n",
       " 0.07677966356277466,\n",
       " 0.08671948313713074,\n",
       " -0.044699810445308685,\n",
       " -0.01393265649676323,\n",
       " 0.04527289420366287,\n",
       " -0.001684844377450645,\n",
       " 0.014145055785775185,\n",
       " -0.056209392845630646,\n",
       " -0.04979588836431503,\n",
       " 0.1003178283572197,\n",
       " 0.027240024879574776,\n",
       " 0.04167032614350319,\n",
       " 0.03735371306538582,\n",
       " 0.019976675510406494,\n",
       " -0.08719607442617416,\n",
       " 0.04335483908653259,\n",
       " -0.014353770762681961,\n",
       " -0.046559613198041916,\n",
       " 0.010446807369589806,\n",
       " 0.022575806826353073,\n",
       " 0.03533715754747391,\n",
       " -0.03787144646048546,\n",
       " -0.02565709874033928,\n",
       " 0.06653374433517456,\n",
       " -0.039680276066064835,\n",
       " 0.04354194179177284,\n",
       " 0.005344504024833441,\n",
       " 0.013428198173642159,\n",
       " 0.004189557861536741,\n",
       " 0.08886692672967911,\n",
       " 0.02260122075676918,\n",
       " 0.09219765663146973,\n",
       " 0.04931429773569107,\n",
       " 0.02579250931739807,\n",
       " -0.08958637714385986,\n",
       " -0.00011975318193435669,\n",
       " 0.04394886642694473,\n",
       " -0.02728596143424511,\n",
       " 0.13635890185832977,\n",
       " 0.03642971068620682,\n",
       " -0.012534178793430328,\n",
       " 0.018802782520651817,\n",
       " 0.06753197312355042,\n",
       " 0.054757509380578995,\n",
       " 0.04160604998469353,\n",
       " 0.1049371063709259,\n",
       " -0.015908757224678993,\n",
       " -0.030357912182807922,\n",
       " 0.02014056220650673,\n",
       " 0.07694556564092636,\n",
       " -0.020466577261686325,\n",
       " 0.029011959210038185,\n",
       " -0.019167140126228333,\n",
       " -0.09577508270740509,\n",
       " 0.0024616364389657974,\n",
       " -0.024704188108444214,\n",
       " 0.04484402760863304,\n",
       " -0.042620450258255005,\n",
       " -0.017916612327098846,\n",
       " 0.0304452832788229,\n",
       " -0.007965728640556335,\n",
       " -0.06862174719572067,\n",
       " 0.062261004000902176,\n",
       " -0.006398996338248253,\n",
       " 0.0810483768582344,\n",
       " 0.03951457887887955,\n",
       " -0.01961575821042061,\n",
       " -0.04534982144832611,\n",
       " -0.021143784746527672,\n",
       " -0.03715679422020912,\n",
       " -0.030555227771401405,\n",
       " 0.011691072955727577,\n",
       " 1.3118530730501152e-33,\n",
       " -0.051338475197553635,\n",
       " 0.03967674821615219,\n",
       " -0.05802081152796745,\n",
       " 0.08007840067148209,\n",
       " 0.05772955343127251,\n",
       " 0.036416977643966675,\n",
       " 0.09774751216173172,\n",
       " -0.05194148048758507,\n",
       " 0.09447604417800903,\n",
       " -0.008461790159344673,\n",
       " -0.04685533419251442,\n",
       " -0.005348102655261755,\n",
       " 0.00916298571974039,\n",
       " -0.025522354990243912,\n",
       " 0.033051785081624985,\n",
       " 0.005971335340291262,\n",
       " -0.04215158522129059,\n",
       " -0.012835666537284851,\n",
       " -0.12685376405715942,\n",
       " 0.019382497295737267,\n",
       " -0.048033639788627625,\n",
       " 0.034640196710824966,\n",
       " -0.12292179465293884,\n",
       " -0.06291061639785767,\n",
       " -0.005165111739188433,\n",
       " -0.04762004315853119,\n",
       " 0.06190790981054306,\n",
       " 0.01123921200633049,\n",
       " 0.03361845016479492,\n",
       " 0.021977344527840614,\n",
       " 0.09390106052160263,\n",
       " 0.007827816531062126,\n",
       " -0.02403395064175129,\n",
       " -0.0651252418756485,\n",
       " -0.025113584473729134,\n",
       " -0.00419098325073719,\n",
       " 0.051393646746873856,\n",
       " -0.030552947893738747,\n",
       " 0.022532083094120026,\n",
       " 0.017442194744944572,\n",
       " -0.006316951010376215,\n",
       " 0.06060326471924782,\n",
       " 0.014892141334712505,\n",
       " 0.017077216878533363,\n",
       " 0.00046760920668020844,\n",
       " 0.029004354029893875,\n",
       " 0.012065169401466846,\n",
       " -0.005499163642525673,\n",
       " -0.003604886354878545,\n",
       " -0.0915284976363182,\n",
       " 0.061436284333467484,\n",
       " 0.06756184250116348,\n",
       " 0.04538129270076752,\n",
       " -0.04711664095520973,\n",
       " -0.0075693451799452305,\n",
       " -0.03793249651789665,\n",
       " 0.07640771567821503,\n",
       " -0.013089889660477638,\n",
       " -0.13893364369869232,\n",
       " 0.0013343512546271086,\n",
       " 0.029524270445108414,\n",
       " -0.04923400282859802,\n",
       " 0.10766086727380753,\n",
       " 0.06808828562498093,\n",
       " -0.11834167689085007,\n",
       " 0.06224829703569412,\n",
       " -0.005996424704790115,\n",
       " 0.023884747177362442,\n",
       " -0.06084589287638664,\n",
       " -0.0515163280069828,\n",
       " 0.042827803641557693,\n",
       " 0.0020046348217874765,\n",
       " 0.018661536276340485,\n",
       " -0.04451537877321243,\n",
       " -0.03753936290740967,\n",
       " -0.053853970021009445,\n",
       " -0.08037272095680237,\n",
       " 0.004225816112011671,\n",
       " -0.0035174961667507887,\n",
       " 0.015366188250482082,\n",
       " -0.05730123445391655,\n",
       " -0.04859897866845131,\n",
       " 0.008478829637169838,\n",
       " 0.02987861819565296,\n",
       " -0.033836498856544495,\n",
       " 0.05989053100347519,\n",
       " -0.0815470889210701,\n",
       " -0.029208874329924583,\n",
       " -0.06265375763177872,\n",
       " -0.11807309091091156,\n",
       " -0.0749812200665474,\n",
       " -0.08424926549196243,\n",
       " -0.11922156810760498,\n",
       " -0.036842722445726395,\n",
       " 0.017771057784557343,\n",
       " -1.761148915591093e-08,\n",
       " 0.013645532540977001,\n",
       " -0.04701456055045128,\n",
       " 0.03528928384184837,\n",
       " -0.09180453419685364,\n",
       " -0.007383581716567278,\n",
       " 0.030980175361037254,\n",
       " -0.057232245802879333,\n",
       " 0.06974039226770401,\n",
       " -0.019246287643909454,\n",
       " -0.007641637697815895,\n",
       " 0.09945125132799149,\n",
       " -0.007662266492843628,\n",
       " -0.0445781946182251,\n",
       " -0.019857613369822502,\n",
       " 0.0320713110268116,\n",
       " -0.025321880355477333,\n",
       " 0.05988737568259239,\n",
       " -0.01911183074116707,\n",
       " 0.00549730658531189,\n",
       " 0.04519299417734146,\n",
       " 0.04517969861626625,\n",
       " -0.0018179058097302914,\n",
       " -0.05656782537698746,\n",
       " 0.01581665687263012,\n",
       " 0.049334991723299026,\n",
       " 0.0038751191459596157,\n",
       " -0.09622772783041,\n",
       " 0.03337389975786209,\n",
       " -0.05420706048607826,\n",
       " -0.029749929904937744,\n",
       " 0.017560135573148727,\n",
       " -0.05419085547327995,\n",
       " 0.040713340044021606,\n",
       " -0.0366632416844368,\n",
       " 0.04437992349267006,\n",
       " -0.09677083045244217,\n",
       " 0.1088845357298851,\n",
       " -0.015806658193469048,\n",
       " -0.024780970066785812,\n",
       " 0.01826363615691662,\n",
       " 0.009435253217816353,\n",
       " 0.07992105185985565,\n",
       " -0.03742478787899017,\n",
       " 0.10391614586114883,\n",
       " 0.03529783710837364,\n",
       " 0.020906995981931686,\n",
       " 0.02943594381213188,\n",
       " 0.02830200083553791,\n",
       " 0.0764816552400589,\n",
       " 0.03747102990746498,\n",
       " 0.01674887351691723,\n",
       " 0.034679703414440155,\n",
       " -0.023753155022859573,\n",
       " 0.019392067566514015,\n",
       " 0.04926056042313576,\n",
       " 0.0019896903540939093,\n",
       " -0.00039235147414729,\n",
       " -0.03969999775290489,\n",
       " -0.08911903947591782,\n",
       " 0.07246717065572739,\n",
       " -0.003534541931003332,\n",
       " -0.007582970894873142,\n",
       " 0.1028590276837349,\n",
       " -0.03687814623117447]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# query_result = embeddings.embed_query(\"What is the difference between a data scientist and a data engineer?\")\n",
    "\n",
    "# if True: # change to True if you want to (re)create your store   \n",
    "#     vectorstore = FAISS.from_documents(\n",
    "#         documents, embedding=embeddings\n",
    "#     )\n",
    "#     # store because this is slow\n",
    "#     vectorstore.save_local(\"vectorstore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c74ddc-4144-4ff6-a4bf-4f64b9ef1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\"vectorstore\", embeddings)\n",
    "vectorstore.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80908f-1696-461d-98ca-f973038139dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "\n",
    "retriever = vectorstore.as_retriever(k=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf70a1-b150-47bc-af58-9de50d0cd07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(s):\n",
    "    results = retriever.get_relevant_documents(s)\n",
    "    for doc in results:\n",
    "        print(\"#\"*100)\n",
    "        print(doc.metadata[\"source\"])\n",
    "        print(\"#\"*100)\n",
    "        print(doc.page_content)\n",
    "q(\"stochastic gradient descent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b51e1d-d731-4d93-aff5-4a191740e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "q(\"what type of awards does vlerick give\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba6dee-4871-42f4-a22e-371437e57d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da656ab0-eda2-424a-af9f-43d0eb609544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
